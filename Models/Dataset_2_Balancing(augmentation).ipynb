{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQKKADwKIKtU",
        "outputId": "2232128d-9662-4891-a8f2-32ebe7596850"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqmKynZLQDrz",
        "outputId": "1d835117-30cd-41c8-f738-b250b4f24668"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/612.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.22.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QATAzicVdcYz"
      },
      "outputs": [],
      "source": [
        "# Import libraries for data augumentation\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from skimage import exposure\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import time\n",
        "\n",
        "random.seed(123) # random data augumentation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# this function does the job of image zoom augumentation | input:numpy img outut:zoomed numpy img\n",
        "def zoom_augmentation(image, zoom_factor):\n",
        "    # Ensure the zoom factor is within valid range (0.0 to 1.0)\n",
        "    if zoom_factor <= 0.0 or zoom_factor >= 1.0:\n",
        "        raise ValueError(\"Zoom factor must be between 0.0 and 1.0\")\n",
        "\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Calculate the cropping region\n",
        "    crop_height = int(height * zoom_factor)\n",
        "    crop_width = int(width * zoom_factor)\n",
        "\n",
        "    # Calculate the starting point for cropping\n",
        "    start_x = (width - crop_width) // 2\n",
        "    start_y = (height - crop_height) // 2\n",
        "\n",
        "    # Crop the image to achieve zoom\n",
        "    zoomed_image = image[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
        "\n",
        "    # Resize the cropped region back to the original image size\n",
        "    zoomed_image = cv2.resize(zoomed_image, (width, height))\n",
        "    return zoomed_image\n",
        "\n",
        "\n",
        "#--> This function combines many agumentations and output an augumented image in numpy format\n",
        "def augment_image(image,\n",
        "                  rotation_angle=0,\n",
        "                  horizontal_flip=False,\n",
        "                  vertical_flip=False,\n",
        "                  brightness_factor=None,\n",
        "                  apply_hist_eq=False,\n",
        "                  zoom_factor=1.0):\n",
        "\n",
        "    augmented_image= image.copy()\n",
        "\n",
        "    # Rotation\n",
        "    if rotation_angle != 0:\n",
        "        rows, cols, _ = augmented_image.shape\n",
        "        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle, 1)\n",
        "        augmented_image = cv2.warpAffine(augmented_image, M, (cols, rows))\n",
        "\n",
        "\n",
        "    # Horizontal flip\n",
        "    if horizontal_flip:\n",
        "        augmented_image = cv2.flip(augmented_image, 1)\n",
        "\n",
        "\n",
        "    # Vertical flip\n",
        "    if vertical_flip:\n",
        "        augmented_image = cv2.flip(augmented_image, 0)\n",
        "\n",
        "\n",
        "    # Brightness adjustment\n",
        "    if brightness_factor is not None:\n",
        "        augmented_image = cv2.convertScaleAbs(augmented_image, alpha=brightness_factor, beta=0)\n",
        "\n",
        "\n",
        "    # histogram equilization\n",
        "    if apply_hist_eq:\n",
        "        augmented_image = exposure.equalize_adapthist(augmented_image, clip_limit=0.008)\n",
        "        augmented_image = (augmented_image*250).astype('uint8')\n",
        "\n",
        "\n",
        "    # apply zoom\n",
        "    if zoom_factor!=1.0: # lower is no. higher is zoom | 0.0 to 1.0\n",
        "        augmented_image = zoom_augmentation(augmented_image, zoom_factor)\n",
        "\n",
        "\n",
        "    return augmented_image\n",
        "\n",
        "\n",
        "\n",
        "# ## example use of image augumentation displaying below\n",
        "# image = cv2.imread('test/0Normal/NormalG0 (433).png')\n",
        "# image = augment_image(image, brightness_factor=1.0, zoom_factor=1.0, rotation_angle=10, apply_hist_eq=True, horizontal_flip=True, vertical_flip=True)\n",
        "# display(Image.fromarray((image).astype('uint8')))\n",
        "\n"
      ],
      "metadata": {
        "id": "1giV78mEPKNe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --> Function to save augumented images\n",
        "\n",
        "def auto_augument_img(image, generate_qty):\n",
        "    augumented_images = []\n",
        "\n",
        "\n",
        "    # Here is augumentation parameters | modify if needed\n",
        "    rotation_angle = [ +12, 0, -12]\n",
        "    brightness_factor = [1.0, 0.8]\n",
        "    vertical_flip = [False, True]\n",
        "    horizontal_flip = [True]\n",
        "    apply_hist_eq = [False] # if change to [True], also uncomment hist eql. for original img (below code)\n",
        "    zoom_factor = [1.0, 0.9]\n",
        "\n",
        "    total_possible_img_count = len(rotation_angle)* len(brightness_factor)* len(vertical_flip)* len(horizontal_flip)*len(zoom_factor) # 240\n",
        "    skip_factor = generate_qty/total_possible_img_count # 14/240 = 0.0058\n",
        "    for rotatation in rotation_angle:\n",
        "        for bright in brightness_factor:\n",
        "            for v_flip in vertical_flip:\n",
        "                for h_flip in horizontal_flip:\n",
        "                    for zoom in zoom_factor:\n",
        "                        if random.random() < skip_factor: # 0.0058 lower is number more images\n",
        "                            aug_im = augment_image(image, brightness_factor=bright, zoom_factor=zoom, rotation_angle=rotatation, apply_hist_eq=apply_hist_eq, horizontal_flip=h_flip, vertical_flip=v_flip)\n",
        "                            augumented_images.append(aug_im)\n",
        "\n",
        "\n",
        "    return augumented_images\n",
        "\n",
        "\n",
        "# # example use: takes an image_arr and gives list of images after applying different augumentation on them | input and output are np array img\n",
        "# image = cv2.imread('archive/test/0/9003175L.png')\n",
        "# all_imgs = auto_augument_img(image, generate_qty=10)\n",
        "# print('Total no. of images generated: ', len(all_imgs))"
      ],
      "metadata": {
        "id": "ew8vUamuPNsx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing no. of images with data augmentation"
      ],
      "metadata": {
        "id": "H_jXT4Y-ss2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating new image dataset with data augumentation\n",
        "\n",
        "\n",
        "def data_balanceing(output_path, folder_path, max_image):\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    classes = ['0Normal', '1Doubtful', '2Mild', '3Moderate', '4Severe']  # class folder names\n",
        "\n",
        "    for class_ in classes:\n",
        "        img_folder_path = os.path.join(folder_path, str(class_))\n",
        "        image_counter = 0\n",
        "        for img_file in os.listdir(img_folder_path): # loop through every single image in class folder\n",
        "            full_path_img_file = os.path.join(img_folder_path, img_file)\n",
        "            output_folder_cls = os.path.join(output_path, str(class_))\n",
        "\n",
        "            # print(full_path_img_file, output_folder_cls)\n",
        "            os.makedirs(output_folder_cls, exist_ok=True)\n",
        "\n",
        "            if image_counter>max_image:\n",
        "                break # break from this class of image\n",
        "\n",
        "            total_available_img = len(os.listdir(img_folder_path)) # eg: 200\n",
        "            required_img = max(max_image-total_available_img, 0) # eg: 1000 - 200 = 800\n",
        "            required_img = required_img/total_available_img # per img reqire img\n",
        "\n",
        "            # # Original image apply histogram equilization and saving\n",
        "            # original_img = exposure.equalize_adapthist(cv2.imread(full_path_img_file), clip_limit=0.008)\n",
        "            # original_img = (original_img*255).astype('uint8')\n",
        "            # cv2.imwrite(f'{output_folder_cls}/original_{image_counter}.jpg', original_img)\n",
        "            cv2.imwrite(f'{output_folder_cls}/original_{image_counter}.jpg', cv2.imread(full_path_img_file))\n",
        "\n",
        "            image_counter+=1\n",
        "\n",
        "            all_imgs = auto_augument_img(cv2.imread(full_path_img_file), generate_qty=required_img)\n",
        "            for img_arr in all_imgs:\n",
        "                new_img_file_path = f'{output_folder_cls}/aug_{image_counter}.jpg'\n",
        "                cv2.imwrite(new_img_file_path, img_arr)\n",
        "                image_counter+=1\n",
        "\n",
        "            if image_counter>max_image:\n",
        "                break\n",
        "\n",
        "        print(f'Done class {class_} for {folder_path}')\n",
        "\n",
        "\n",
        "\n",
        "data_balanceing(\n",
        "    output_path = \"/content/drive/MyDrive/SHSU-Projects/Final_files/Knee_Dataset_2_Augmented/train_augmented\",\n",
        "    folder_path=\"/content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_2_Original/train\",\n",
        "    max_image=1350\n",
        ")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUCl2LgjfBTy",
        "outputId": "67c3150f-889b-4597-f32c-0d704f1a3536"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done class 0Normal for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_2_Original/train\n",
            "Done class 1Doubtful for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_2_Original/train\n",
            "Done class 2Mild for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_2_Original/train\n",
            "Done class 3Moderate for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_2_Original/train\n",
            "Done class 4Severe for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_2_Original/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to the test folder\n",
        "test_folder_path = '/content/drive/MyDrive/SHSU-Projects/Final_files/Knee_Dataset_2_Augmented/train_augmented'\n",
        "\n",
        "# Get a list of class folders within the test folder\n",
        "class_folders = [folder for folder in os.listdir(test_folder_path) if os.path.isdir(os.path.join(test_folder_path, folder))]\n",
        "\n",
        "# Count the number of images in each class folder\n",
        "class_image_counts = {}\n",
        "for class_folder in class_folders:\n",
        "    class_path = os.path.join(test_folder_path, class_folder)\n",
        "    image_count = len(os.listdir(class_path))\n",
        "    class_image_counts[class_folder] = image_count\n",
        "\n",
        "# Display the image counts for each class\n",
        "for class_folder, count in class_image_counts.items():\n",
        "    print(f\"Class {class_folder}: {count} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz9EzjwEvtFN",
        "outputId": "c64f018f-e647-4e4c-9961-5ccc983b3e6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0Normal: 1351 images\n",
            "Class 1Doubtful: 1347 images\n",
            "Class 2Mild: 1338 images\n",
            "Class 3Moderate: 1334 images\n",
            "Class 4Severe: 1355 images\n"
          ]
        }
      ]
    }
  ]
}