{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQKKADwKIKtU",
        "outputId": "516f6bf0-4448-4573-d897-014b9e1428f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QATAzicVdcYz"
      },
      "outputs": [],
      "source": [
        "# Import libraries for data augumentation\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from skimage import exposure\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import time\n",
        "\n",
        "random.seed(123) # random data augumentation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# this function does the job of image zoom augumentation | input:numpy img outut:zoomed numpy img\n",
        "def zoom_augmentation(image, zoom_factor):\n",
        "    # Ensure the zoom factor is within valid range (0.0 to 1.0)\n",
        "    if zoom_factor <= 0.0 or zoom_factor >= 1.0:\n",
        "        raise ValueError(\"Zoom factor must be between 0.0 and 1.0\")\n",
        "\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Calculate the cropping region\n",
        "    crop_height = int(height * zoom_factor)\n",
        "    crop_width = int(width * zoom_factor)\n",
        "\n",
        "    # Calculate the starting point for cropping\n",
        "    start_x = (width - crop_width) // 2\n",
        "    start_y = (height - crop_height) // 2\n",
        "\n",
        "    # Crop the image to achieve zoom\n",
        "    zoomed_image = image[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
        "\n",
        "    # Resize the cropped region back to the original image size\n",
        "    zoomed_image = cv2.resize(zoomed_image, (width, height))\n",
        "    return zoomed_image\n",
        "\n",
        "\n",
        "#--> This function combines many agumentations and output an augumented image in numpy format\n",
        "def augment_image(image,\n",
        "                  rotation_angle=0,\n",
        "                  horizontal_flip=False,\n",
        "                  vertical_flip=False,\n",
        "                  brightness_factor=None,\n",
        "                  apply_hist_eq=False,\n",
        "                  zoom_factor=1.0):\n",
        "\n",
        "    augmented_image= image.copy()\n",
        "\n",
        "    # Rotation\n",
        "    if rotation_angle != 0:\n",
        "        rows, cols, _ = augmented_image.shape\n",
        "        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle, 1)\n",
        "        augmented_image = cv2.warpAffine(augmented_image, M, (cols, rows))\n",
        "\n",
        "\n",
        "    # Horizontal flip\n",
        "    if horizontal_flip:\n",
        "        augmented_image = cv2.flip(augmented_image, 1)\n",
        "\n",
        "\n",
        "    # Vertical flip\n",
        "    if vertical_flip:\n",
        "        augmented_image = cv2.flip(augmented_image, 0)\n",
        "\n",
        "\n",
        "    # Brightness adjustment\n",
        "    if brightness_factor is not None:\n",
        "        augmented_image = cv2.convertScaleAbs(augmented_image, alpha=brightness_factor, beta=0)\n",
        "\n",
        "\n",
        "    # histogram equilization\n",
        "    if apply_hist_eq:\n",
        "        augmented_image = exposure.equalize_adapthist(augmented_image, clip_limit=0.008)\n",
        "        augmented_image = (augmented_image*250).astype('uint8')\n",
        "\n",
        "\n",
        "    # apply zoom\n",
        "    if zoom_factor!=1.0: # lower is no. higher is zoom | 0.0 to 1.0\n",
        "        augmented_image = zoom_augmentation(augmented_image, zoom_factor)\n",
        "\n",
        "\n",
        "    return augmented_image\n",
        "\n",
        "\n",
        "\n",
        "# ## example use of image augumentation displaying below\n",
        "# image = cv2.imread('knee-xray/MedicalExpert-I-modified/test/0Normal/NormalG0 (433).png')\n",
        "# image = augment_image(image, brightness_factor=1.0, zoom_factor=1.0, rotation_angle=10, apply_hist_eq=True, horizontal_flip=True, vertical_flip=True)\n",
        "# display(Image.fromarray((image).astype('uint8')))\n",
        "\n"
      ],
      "metadata": {
        "id": "W9JZZ_8KosSe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --> Function to save augumented images\n",
        "\n",
        "def auto_augument_img(image, generate_qty):\n",
        "    augumented_images = []\n",
        "\n",
        "\n",
        "    # Here is augumentation parameters | modify if needed\n",
        "    rotation_angle = [ +12, 0, -12]\n",
        "    brightness_factor = [1.0, 0.8]\n",
        "    vertical_flip = [False, True]\n",
        "    horizontal_flip = [True]\n",
        "    apply_hist_eq = [False] # if change to [True], also uncomment hist eql. for original img (below code)\n",
        "    zoom_factor = [1.0, 0.9]\n",
        "\n",
        "    total_possible_img_count = len(rotation_angle)* len(brightness_factor)* len(vertical_flip)* len(horizontal_flip)*len(zoom_factor) # 240\n",
        "    skip_factor = generate_qty/total_possible_img_count # 14/240 = 0.0058\n",
        "    for rotatation in rotation_angle:\n",
        "        for bright in brightness_factor:\n",
        "            for v_flip in vertical_flip:\n",
        "                for h_flip in horizontal_flip:\n",
        "                    for zoom in zoom_factor:\n",
        "                        if random.random() < skip_factor: # 0.0058 lower is number more images\n",
        "                            aug_im = augment_image(image, brightness_factor=bright, zoom_factor=zoom, rotation_angle=rotatation, apply_hist_eq=apply_hist_eq, horizontal_flip=h_flip, vertical_flip=v_flip)\n",
        "                            augumented_images.append(aug_im)\n",
        "\n",
        "\n",
        "    return augumented_images\n",
        "\n",
        "\n",
        "# # example use: takes an image_arr and gives list of images after applying different augumentation on them | input and output are np array img\n",
        "# image = cv2.imread('archive/test/0/9003175L.png')\n",
        "# all_imgs = auto_augument_img(image, generate_qty=10)\n",
        "# print('Total no. of images generated: ', len(all_imgs))"
      ],
      "metadata": {
        "id": "mmQEctDYov7r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing no. of images with data augmentation"
      ],
      "metadata": {
        "id": "y7e0gvkBozpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating new image dataset with data augumentation\n",
        "\n",
        "\n",
        "def data_balanceing(output_path, folder_path, max_image):\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    classes = ['0', '1', '2', '3', '4']  # class folder names\n",
        "\n",
        "    for class_ in classes:\n",
        "        img_folder_path = os.path.join(folder_path, str(class_))\n",
        "        image_counter = 0\n",
        "        for img_file in os.listdir(img_folder_path): # loop through every single image in class folder\n",
        "            full_path_img_file = os.path.join(img_folder_path, img_file)\n",
        "            output_folder_cls = os.path.join(output_path, str(class_))\n",
        "\n",
        "            # print(full_path_img_file, output_folder_cls)\n",
        "            os.makedirs(output_folder_cls, exist_ok=True)\n",
        "\n",
        "            if image_counter>max_image:\n",
        "                break # break from this class of image\n",
        "\n",
        "            total_available_img = len(os.listdir(img_folder_path)) # eg: 200\n",
        "            required_img = max(max_image-total_available_img, 0) # eg: 1000 - 200 = 800\n",
        "            required_img = required_img/total_available_img # per img reqire img\n",
        "\n",
        "            # # Original image apply histogram equilization and saving\n",
        "            # original_img = exposure.equalize_adapthist(cv2.imread(full_path_img_file), clip_limit=0.008)\n",
        "            # original_img = (original_img*255).astype('uint8')\n",
        "            # cv2.imwrite(f'{output_folder_cls}/original_{image_counter}.jpg', original_img)\n",
        "            cv2.imwrite(f'{output_folder_cls}/original_{image_counter}.jpg', cv2.imread(full_path_img_file))\n",
        "\n",
        "            image_counter+=1\n",
        "\n",
        "            all_imgs = auto_augument_img(cv2.imread(full_path_img_file), generate_qty=required_img)\n",
        "            for img_arr in all_imgs:\n",
        "                new_img_file_path = f'{output_folder_cls}/aug_{image_counter}.jpg'\n",
        "                cv2.imwrite(new_img_file_path, img_arr)\n",
        "                image_counter+=1\n",
        "\n",
        "            if image_counter>max_image:\n",
        "                break\n",
        "\n",
        "        print(f'Done class {class_} for {folder_path}')\n",
        "\n",
        "\n",
        "\n",
        "# Balanceing Train dataset with augmented images\n",
        "\n",
        "data_balanceing(\n",
        "    output_path = \"/content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Augmented/Train_Augmented\",\n",
        "    folder_path=\"/content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/train\",\n",
        "    max_image=1400\n",
        ")"
      ],
      "metadata": {
        "id": "fEoc08Rbo00Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2d11b2-62ab-4ff6-c177-576552eb7044"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done class 0 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/train\n",
            "Done class 1 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/train\n",
            "Done class 2 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/train\n",
            "Done class 3 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/train\n",
            "Done class 4 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Balanceing Validation dataset with augmented images**"
      ],
      "metadata": {
        "id": "JYJZSsMwpIEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_balanceing(\n",
        "    output_path = \"/content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Augmented/Val_Augmented\",\n",
        "    folder_path=\"/content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/val\",\n",
        "    max_image=500\n",
        ")"
      ],
      "metadata": {
        "id": "5E28LKtGpCVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183ca508-da91-4348-e3eb-3d28535edb91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done class 0 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/val\n",
            "Done class 1 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/val\n",
            "Done class 2 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/val\n",
            "Done class 3 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/val\n",
            "Done class 4 for /content/drive/MyDrive/SHSU-Projects/Final_files/KneeOA_Dataset_1_Original/val\n"
          ]
        }
      ]
    }
  ]
}